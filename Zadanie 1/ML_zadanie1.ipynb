{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4806221c",
   "metadata": {},
   "source": [
    "### Szablon funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aab2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "class RidgeRegr:\n",
    "    def __init__(self, alpha = 0.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # wejscie:\n",
    "        #  X = np.array, shape = (n, m)\n",
    "        #  Y = np.array, shape = (n)\n",
    "        # Znajduje theta (w przyblizeniu) minimalizujace kwadratowa funkcje kosztu L uzywajac metody iteracyjnej.\n",
    "        n, m = X.shape\n",
    "        self.theta = np.zeros((m+1))\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # wejscie\n",
    "        #  X = np.array, shape = (k, m)\n",
    "        # zwraca\n",
    "        #  Y = wektor(f(X_1), ..., f(X_k))\n",
    "        k, m = X.shape\n",
    "        return np.zeros((k))\n",
    "\n",
    "\n",
    "def test_RidgeRegressionInOneDim():\n",
    "    X = np.array([1,3,2,5]).reshape((4,1))\n",
    "    Y = np.array([2,5, 3, 8])\n",
    "    X_test = np.array([1,2,10]).reshape((3,1))\n",
    "    alpha = 0.3\n",
    "    expected = Ridge(alpha).fit(X, Y).predict(X_test)\n",
    "    actual = RidgeRegr(alpha).fit(X, Y).predict(X_test)\n",
    "    assert list(actual) == pytest.approx(list(expected), rel=1e-5)\n",
    "\n",
    "def test_RidgeRegressionInThreeDim():\n",
    "    X = np.array([1,2,3,5,4,5,4,3,3,3,2,5]).reshape((4,3))\n",
    "    Y = np.array([2,5, 3, 8])\n",
    "    X_test = np.array([1,0,0, 0,1,0, 0,0,1, 2,5,7, -2,0,3]).reshape((5,3))\n",
    "    alpha = 0.4\n",
    "    expected = Ridge(alpha).fit(X, Y).predict(X_test)\n",
    "    actual = RidgeRegr(alpha).fit(X, Y).predict(X_test)\n",
    "    assert list(actual) == pytest.approx(list(expected), rel=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a838d5",
   "metadata": {},
   "source": [
    "## Implementacja Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4931048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177\n",
      "[ 1.88950276  3.38121547 15.31491713]\n",
      "[ 1.88950356  3.38121595 15.31491504]\n",
      "----------\n",
      "6177\n",
      "[ 0.54685378 -1.76188321  1.58691716  5.15527388  3.66704391]\n",
      "[ 0.54684662 -1.76188799  1.58691183  5.15528139  3.66704223]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "class RidgeRegr:\n",
    "    # Musimy przypisać atrybuty do obiektu, alpha, c, tol, max_iter\n",
    "    def __init__(self, alpha = 0.0, c=0.001, max_iter = 50000, tol = 1e-8):\n",
    "        self.alpha = alpha\n",
    "        self.c = c\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # wejscie:\n",
    "        #  X = np.array, shape = (n, m)\n",
    "        #  Y = np.array, shape = (n)\n",
    "        # Znajduje theta (w przyblizeniu) minimalizujace kwadratowa funkcje kosztu L uzywajac metody iteracyjnej.\n",
    "        n, m = X.shape\n",
    "\n",
    "        # Do X dodajemy kolumnę wyrazów wolnych\n",
    "        X_z_1 = np.column_stack([np.ones(n),X])\n",
    "\n",
    "        # Wybieramy jakieś początkowe thety\n",
    "        self.theta = np.zeros((m+1))\n",
    "        \n",
    "    \n",
    "        # Optymalizujemy thety\n",
    "        for iteracja in range(self.max_iter):\n",
    "            y_szacowane = X_z_1 @ self.theta\n",
    "\n",
    "            # Liczymy gradient\n",
    "            gradient = np.zeros(m+1) # m+1 współczynników (theta_0, ..., theta_m)\n",
    "\n",
    "            # Pochodna po theta_0:  suma{i=1}{n} (f(x_i)-yi) \n",
    "            gradient[0] = sum(y_szacowane-Y)\n",
    "\n",
    "            # Pochodne dla theta_1, ..., theta_m. Dla theta_j  suma{i=1}{n} ( xij * [f(x_i)-yi] ) + alfa*theta_j\n",
    "            # j jest ustalone dla danego theta, zmienia się i\n",
    "            for j in range(1, m+1):\n",
    "                gradient[j] = np.sum( X_z_1[:, j] * (y_szacowane-Y) ) + self.alpha*self.theta[j]\n",
    "\n",
    "            # Aktualizujemy parametry\n",
    "            nowe_theta = self.theta - self.c * gradient\n",
    "\n",
    "            # Sprawdzamy, czy odległość euklidesowa jest mniejsza od zadanej tolerancji, tzn. czy theta się zmienia w znaczącym stopniu\n",
    "            if np.linalg.norm(nowe_theta - self.theta) < self.tol:\n",
    "                print(iteracja)\n",
    "                break\n",
    "\n",
    "            # Ustawiamy nowe, lepsze theta\n",
    "            self.theta = nowe_theta\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # wejscie\n",
    "        #  X = np.array, shape = (k, m)\n",
    "        # zwraca\n",
    "        #  Y = wektor(f(X_1), ..., f(X_k))\n",
    "        k, m = X.shape\n",
    "        X_z_1 = np.column_stack([np.ones(k),X])\n",
    "        # Wyznaczamy wektor Y na podstawie dopasowanego wektora theta\n",
    "        return X_z_1 @ self.theta\n",
    "\n",
    "\n",
    "def test_RidgeRegressionInOneDim():\n",
    "    X = np.array([1,3,2,5]).reshape((4,1))\n",
    "    Y = np.array([2,5, 3, 8])\n",
    "    X_test = np.array([1,2,10]).reshape((3,1))\n",
    "    alpha = 0.3\n",
    "    expected = Ridge(alpha).fit(X, Y).predict(X_test)\n",
    "    actual = RidgeRegr(alpha, c=0.01, max_iter=20000).fit(X, Y).predict(X_test)\n",
    "    print(expected)\n",
    "    print(actual)\n",
    "    assert list(actual) == pytest.approx(list(expected), rel=1e-5)\n",
    "    \n",
    "def test_RidgeRegressionInThreeDim():\n",
    "    X = np.array([1,2,3,5,4,5,4,3,3,3,2,5]).reshape((4,3))\n",
    "    Y = np.array([2,5, 3, 8])\n",
    "    X_test = np.array([1,0,0, 0,1,0, 0,0,1, 2,5,7, -2,0,3]).reshape((5,3))\n",
    "    alpha = 0.4\n",
    "    expected = Ridge(alpha).fit(X, Y).predict(X_test)\n",
    "    actual = RidgeRegr(alpha, c=0.01, max_iter=80000).fit(X, Y).predict(X_test)\n",
    "    print(expected)\n",
    "    print(actual)\n",
    "    assert list(actual) == pytest.approx(list(expected), rel=1e-3)\n",
    "\n",
    "test_RidgeRegressionInOneDim()\n",
    "# Dla początkowego wektora theta (1,1,...,1)\n",
    "# Dla c=0.01 wystarczy 1556 iteracji, dla c=0.001 potrzeba 12913 iteracji\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "test_RidgeRegressionInThreeDim() \n",
    "# Dla c=0.01 wystarczy 7662 iteracji, dla c=0.001 potrzeba 61186 iteracji\n",
    "\n",
    "# Nie wyrzuciło wyjątku, zatem funkcja RidgeRegr() poprawnie przeszła testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df79cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
