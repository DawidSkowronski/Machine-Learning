{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21de666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6d5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_treningowe, dane_walidacyjne, dane_testowe = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a520be",
   "metadata": {},
   "source": [
    "W danych treningowych y to jest liczba, natomiast w danych testowych y to wektor długości 10\n",
    "\n",
    "Dlatego zmieniamy to w pliku `mnist_loader.py` aby w obu przypadkach mieć wektor długości 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db907ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091c07bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "dane_treningowe = list(dane_treningowe)\n",
    "dane_walidacyjne = list(dane_walidacyjne)\n",
    "dane_testowe = list(dane_testowe)\n",
    "\n",
    "print(len(dane_treningowe)) \n",
    "print(len(dane_walidacyjne))\n",
    "print(len(dane_testowe)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3544b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dane_treningowe[1][0].shape) # wymiar danych\n",
    "print(dane_treningowe[1][1].shape) # wymiar etykiety\n",
    "# Czyli mamy wektory kolumnowe\n",
    "\n",
    "# Trzeba je przekonwertować na wierszowe\n",
    "\n",
    "# Mozna to zmienić w load_data_wrapper()\n",
    "# Można też robić to w sieci (na razie ten wariant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ae1d0",
   "metadata": {},
   "source": [
    "#### Definiujemy byty\n",
    "\n",
    "* Warstwa, metody:\n",
    "1. forward propagation\n",
    "2. back propagation\n",
    "\n",
    " Warstwa powinna mieć atrybuty:\n",
    "- wagi\n",
    "- dane_na_wejsciu (zapamietać)\n",
    "- dane_na_wyjsciu (przekazujemy)\n",
    "- liczba neuronow\n",
    "- funkcja aktywacji\n",
    "- net (zapamiętać)\n",
    "\n",
    "Zapamiętać np. w liście\n",
    "\n",
    "* Sieć (składa sie z wielu Warstw), metody\n",
    "1. forward prop - wykonujemy na każdej z warstw\n",
    "2. backward prop - wykonujemy na każdej z warstw\n",
    "3. fit\n",
    "4. predict\n",
    "5. dokladnosc\n",
    "\n",
    "* Czy dobre byłoby także znormalizować dane, aby przyjmowały wartości z przedziału [0,1]?\n",
    " W ten sposób zminimalizujemy ryzyko liczenia gradientów o bardzo dużych wartościach. Pytanie czy wtedy trzeba generować dane z rozkladu $\\mathcal{N}(0,1/\\sqrt{n})$, n - liczba danych na wejściu\n",
    " Czy wystarczy $\\mathcal{N}(0,1)$\n",
    "\n",
    " * Czy aktualizację wag lepiej jest robić w osobnej funkcji w klasie Warstwa, czy podczas back_prop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee0f8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wygeneruj_wagi(wymiar_wejscie, wymiar_wyjscie):\n",
    "    # wyjściem jest liczba neuronów w następnej warstwie\n",
    "    wektor_wag = np.random.normal(0,1/math.sqrt(wymiar_wejscie),(1+wymiar_wejscie)*wymiar_wyjscie)\n",
    "    return np.reshape(wektor_wag, (wymiar_wyjscie, 1+wymiar_wejscie )  )\n",
    "\n",
    "# Definiujemy funkcje aktywacji fi (sigmoid)\n",
    "# fi' = fi*(1-fi) \n",
    "def sigmoid(x): return (1+np.exp(-x))**(-1) \n",
    "\n",
    "def deriv_sigmoid(x): return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa28b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiecNeuronowa:\n",
    "    def __init__(self, wymiary = [784, 128, 64, 10]):\n",
    "        # definiujemy listę obiektów warstwy\n",
    "        self.warstwy = list()\n",
    "        # Może każdej warstwy definiujemy funkcję aktywacji? (W ten sposób można wykorzystać różne funkcje)\n",
    "\n",
    "        for i in range(len(wymiary)-1):\n",
    "            warstwa = Warstwa(wymiary[i+1], wymiary[i])\n",
    "            self.warstwy.append(warstwa)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        wyjscie = X\n",
    "        \n",
    "        for warstwa in self.warstwy:\n",
    "            wyjscie = warstwa.forward_prop(wyjscie)\n",
    "        return wyjscie\n",
    "            \n",
    "\n",
    "    def backward_propagation(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def dokladnosc(self):\n",
    "        pass\n",
    "\n",
    "class Warstwa:\n",
    "    def __init__(self, liczba_neuronow, dane_wejscie):\n",
    "        \"\"\"liczba neuronów - w warstwie (czyli liczba danych na wyjściu)\"\"\"\n",
    "        self.liczba_neuronow = liczba_neuronow\n",
    "\n",
    "        self.dane_wejscie = dane_wejscie\n",
    "        self.liczba_wejscie = len(self.dane_wejscie)\n",
    "        # Ustalamy stałą uczenia dla całej warstwy\n",
    "        self.stala_uczenia = 0.1\n",
    "\n",
    "        # Inicjalizacja wag\n",
    "        self.wagi = wygeneruj_wagi(self.dane_wejscie, self.liczba_neuronow)\n",
    "\n",
    "        # Rzeczy do zapamiętania\n",
    "        self.lista_dane_wejscie = list()\n",
    "        self.lista_net = list()\n",
    "    \n",
    "\n",
    "    def fun_aktywacji(self, x): return sigmoid(x)\n",
    "\n",
    "    def pochodna_fun_aktywacji(self, x): return deriv_sigmoid(x)\n",
    "\n",
    "    def forward_prop(self, dane_wejscie ):\n",
    "        \"\"\"Definiujemy propagację w przód.\n",
    "        Podajemy dane na wejście, dodajemy na bias = 1 na początek wektora (otrzymujemy w ten sposób X).\n",
    "        Zadajemy najpierw ile chcemy mieć neuronów na wyjściu\n",
    "        Nastepnie liczymy net = W*X <- wyjście netto.\n",
    "        Póżniej nakładamy funkcję aktywacji fi na net, otrzymując fi(net) = a <- wyjście z warstwy.\n",
    "        Musimy też zapisywać stany x, net, a dla każdej warstwy (np. listy)\"\"\"\n",
    "\n",
    "        # Musimy przerobić X na wektor kolumnowy\n",
    "        self.X = np.vstack([1, dane_wejscie.reshape(-1,1)])\n",
    "        self.net = self.wagi @ self.X\n",
    "        dane_wyjscie = self.fun_aktywacji(self.net)\n",
    "\n",
    "        self.lista_net.append(self.net)\n",
    "        self.lista_dane_wejscie.append(self.X)\n",
    "\n",
    "        self.wyjscia_forward_prop = dane_wyjscie\n",
    "\n",
    "        return dane_wyjscie\n",
    "    \n",
    "    def back_prop(self, wyjscie_oczekiwane):\n",
    "        \"\"\"Definiujemy propagację wstecz.\n",
    "        W ostatniej warstwie liczymy funkcję straty, następnie pochodną dL/da.\"\"\"\n",
    "        \n",
    "        # Funkcja straty to L = 1/2(a[L]-y)^2, czyli pochodna z L to a[L]-y\n",
    "        dL_a = self.wyjscia_forward_prop - wyjscie_oczekiwane\n",
    "\n",
    "        # mamy pochodną dL/da * fi(net)\n",
    "        delta = dL_a * self.pochodna_fun_aktywacji( self.net )\n",
    "        dL_dW = delta @ self.X.T\n",
    "\n",
    "        # Liczymy dL/dX i usuwamy pierwszy element, otrzymując dL/da niższej warstwy\n",
    "        dL_dX = self.wagi.T @ delta\n",
    "        \n",
    "        # Dane do przekazania warstwę niżej\n",
    "        dL_a = dL_dX[1:]\n",
    "\n",
    "        # Aktualizujemy wagi\n",
    "        self.wagi = self.wagi - self.stala_uczenia * dL_dW\n",
    "\n",
    "        return dL_a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c690fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,0]).reshape(2,1)\n",
    "y = np.array([0,1]).reshape(2,1)\n",
    "W1 = np.array([[-0.1, -0.2, 0.1],\n",
    "               [-0.4, 0.7, -0.6]])\n",
    "W2 = np.array([[-0.15, -0.25, 0.15],\n",
    "               [-0.45, 0.75, -0.65]])\n",
    "X1 = np.vstack((1,x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b45c68e",
   "metadata": {},
   "source": [
    "#### Lepiej będzie chyba podawać w `__init__` Warstwa liczbę danych na wejściu i liczbę neuronów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Warstwa:\n",
    "    def __init__(self, liczba_wejscie, liczba_neuronow):\n",
    "        \"\"\"liczba neuronów - w warstwie (czyli liczba danych na wyjściu)\"\"\"\n",
    "        self.liczba_neuronow = liczba_neuronow\n",
    "\n",
    "        self.liczba_wejscie = liczba_wejscie\n",
    "        \n",
    "        # Ustalamy stałą uczenia dla całej warstwy\n",
    "        self.stala_uczenia = 0.1\n",
    "\n",
    "        # Inicjalizacja wag\n",
    "        self.wagi = wygeneruj_wagi(self.liczba_wejscie, self.liczba_neuronow)\n",
    "        print(f\"wagi: {self.wagi.shape}\")\n",
    "\n",
    "        # Rzeczy do zapamiętania,\n",
    "        #  Może wystarczy zapamiętać tylko ostatnie wartosci\n",
    "        self.lista_dane_wejscie = list()\n",
    "        self.lista_net = list()\n",
    "        self.wyjscie_forward_prop = None\n",
    "    \n",
    "\n",
    "    def fun_aktywacji(self, x): return sigmoid(x)\n",
    "\n",
    "    def pochodna_fun_aktywacji(self, x): return deriv_sigmoid(x)\n",
    "\n",
    "    def forward_prop(self, dane_wejscie ):\n",
    "        \"\"\"Definiujemy propagację w przód.\n",
    "        Podajemy dane na wejście, dodajemy na bias = 1 na początek wektora (otrzymujemy w ten sposób X).\n",
    "        Zadajemy najpierw ile chcemy mieć neuronów na wyjściu\n",
    "        Nastepnie liczymy net = W*X <- wyjście netto.\n",
    "        Póżniej nakładamy funkcję aktywacji fi na net, otrzymując fi(net) = a <- wyjście z warstwy.\n",
    "        Musimy też zapisywać stany x, net, a dla każdej warstwy (np. listy)\"\"\"\n",
    "\n",
    "        # Musimy przerobić X na wektor kolumnowy\n",
    "        self.X = np.vstack([1, dane_wejscie.reshape(-1,1)])\n",
    "        self.net = self.wagi @ self.X\n",
    "        dane_wyjscie = self.fun_aktywacji(self.net)\n",
    "\n",
    "        self.lista_net.append(self.net)\n",
    "        self.lista_dane_wejscie.append(self.X)\n",
    "\n",
    "        self.wyjscie_forward_prop = dane_wyjscie\n",
    "\n",
    "        return dane_wyjscie\n",
    "    \n",
    "    def back_prop(self, wyjscie_oczekiwane, czy_warstwa_wyjsciowa = False):\n",
    "        \"\"\"Definiujemy propagację wstecz.\n",
    "        W ostatniej warstwie liczymy funkcję straty, następnie pochodną dL/da.\"\"\"\n",
    "        \n",
    "        # Funkcja straty to L = 1/2(a[L]-y)^2, czyli pochodna z L to a[L]-y\n",
    "\n",
    "        # Ten fragment chyba nie jest potrzeby\n",
    "        dL_a = wyjscie_oczekiwane\n",
    "        #dL_a = self.wyjscia_forward_prop - wyjscie_oczekiwane\n",
    "        #print(\"dL_a\")\n",
    "        #print(dL_a)\n",
    "\n",
    "        if czy_warstwa_wyjsciowa == True:\n",
    "            dL_a = wyjscie_oczekiwane * self.pochodna_fun_aktywacji(self.net)\n",
    "        else:\n",
    "            wagi_bez_biasu = self.wagi[:, 1:] #pomijamy wagę dla biasu\n",
    "\n",
    "        # mamy pochodną dL/da * fi(net)\n",
    "        delta = dL_a * self.pochodna_fun_aktywacji( self.net )\n",
    "        print(\"delta\")\n",
    "        print(delta)\n",
    "\n",
    "        dL_dW = delta @ self.X.T\n",
    "        print(\"dL_dW\")\n",
    "        print(dL_dW)\n",
    "\n",
    "        # Liczymy dL/dX i usuwamy pierwszy element, otrzymując dL/da niższej warstwy\n",
    "        dL_dX = self.wagi.T @ delta\n",
    "        \n",
    "        # Dane do przekazania warstwę niżej\n",
    "        dL_a = dL_dX[1:]\n",
    "\n",
    "        # Aktualizujemy wagi\n",
    "        self.wagi = self.wagi - self.stala_uczenia * dL_dW\n",
    "\n",
    "        return dL_a\n",
    "    \n",
    "\n",
    "class SiecNeuronowa:\n",
    "    def __init__(self, wymiary = [784, 128, 64, 10]):\n",
    "        # definiujemy listę obiektów warstwy\n",
    "        self.warstwy = list()\n",
    "        # Może każdej warstwy definiujemy funkcję aktywacji? (W ten sposób można wykorzystać różne funkcje)\n",
    "\n",
    "        for i in range(len(wymiary)-1):\n",
    "            warstwa = Warstwa(wymiary[i], wymiary[i+1]) # Liczba na wejście i na wyjście\n",
    "            self.warstwy.append(warstwa)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        wyjscie = X\n",
    "        \n",
    "        for warstwa in self.warstwy:\n",
    "            wyjscie = warstwa.forward_prop(wyjscie)\n",
    "            print(\"wyjscie z warstwy\")\n",
    "            print(wyjscie)\n",
    "        return wyjscie\n",
    "            \n",
    "\n",
    "    def backward_propagation(self, y):\n",
    "\n",
    "        ostatnie_wyjscie = self.warstwy[-1].wyjscia_forward_prop\n",
    "\n",
    "        dL_da = ostatnie_wyjscie - y\n",
    "\n",
    "        for i in range(len(self.warstwy) - 1, -1, -1):\n",
    "            dL_da = self.warstwy[i].back_prop(dL_da)\n",
    "        # Pytanie czy musi tu być niższe dL_da, czy podmieniamy obecne?\n",
    "        return dL_da\n",
    "    \n",
    "    def krok_uczenia(self, X, y):\n",
    "        \"\"\"Definiujemy pętlę dla jednej epoki\"\"\"\n",
    "\n",
    "        # Forward prop\n",
    "        y_estymowany = self.forward_propagation(X)\n",
    "\n",
    "        # Strata\n",
    "        strata = np.mean((y_estymowany - y)**2)\n",
    "\n",
    "        # Back prop\n",
    "        self.backward_propagation(y)\n",
    "\n",
    "        return strata # zwracamy wartośc funkcji straty\n",
    "\n",
    "    def fit(self, X, y, epoki = 10):\n",
    "        \"\"\"Przeprowadzamy fit() dla wielu epok\"\"\"\n",
    "\n",
    "        for epoka in range(epoki):\n",
    "\n",
    "            strata_w_epoce = 0\n",
    "            \n",
    "            # W każdej epoce \"mieszamy\" dane\n",
    "            # W tym celu \"mieszamy\" indeksy\n",
    "            indeksy = np.random.permutation(len(X))\n",
    "            X_tasowane = X[indeksy]\n",
    "            y_tasowane = y[indeksy]\n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def dokladnosc(self):\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfae79",
   "metadata": {},
   "source": [
    "### Wersja pod mini-batch'e - gotowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "167e18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wygeneruj_wagi(wymiar_wejscie, wymiar_wyjscie):\n",
    "    # wyjściem jest liczba neuronów w następnej warstwie\n",
    "    wektor_wag = np.random.normal(0,1/math.sqrt(wymiar_wejscie),(1+wymiar_wejscie)*wymiar_wyjscie)\n",
    "    return np.reshape(wektor_wag, (wymiar_wyjscie, 1+wymiar_wejscie )  )\n",
    "\n",
    "# Definiujemy funkcje aktywacji fi (sigmoid)\n",
    "# fi' = fi*(1-fi) \n",
    "def sigmoid(x): return (1+np.exp(-x))**(-1) \n",
    "\n",
    "def deriv_sigmoid(x): return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "\n",
    "class Warstwa:\n",
    "    def __init__(self, liczba_wejscie, liczba_neuronow):\n",
    "        \"\"\"liczba neuronów - w warstwie (czyli liczba danych na wyjściu)\"\"\"\n",
    "        self.liczba_neuronow = liczba_neuronow\n",
    "\n",
    "        self.liczba_wejscie = liczba_wejscie\n",
    "        \n",
    "        # Ustalamy stałą uczenia dla całej warstwy\n",
    "        self.stala_uczenia = 0.1\n",
    "\n",
    "        # Inicjalizacja wag\n",
    "        self.wagi = wygeneruj_wagi(self.liczba_wejscie, self.liczba_neuronow)\n",
    "\n",
    "        # Rzeczy do zapamiętania,\n",
    "        #  Może wystarczy zapamiętać tylko ostatnie wartosci\n",
    "        self.lista_dane_wejscie = list()\n",
    "        self.lista_net = list()\n",
    "    \n",
    "\n",
    "    def fun_aktywacji(self, x): return sigmoid(x)\n",
    "\n",
    "    def pochodna_fun_aktywacji(self, x): return deriv_sigmoid(x)\n",
    "\n",
    "    def forward_prop(self, dane_wejscie ):\n",
    "        \"\"\"Definiujemy propagację w przód.\n",
    "        Podajemy dane na wejście, dodajemy na bias = 1 na początek wektora (otrzymujemy w ten sposób X).\n",
    "        Zadajemy najpierw ile chcemy mieć neuronów na wyjściu\n",
    "        Nastepnie liczymy net = W*X <- wyjście netto.\n",
    "        Póżniej nakładamy funkcję aktywacji fi na net, otrzymując fi(net) = a <- wyjście z warstwy.\n",
    "        Musimy też zapisywać stany x, net, a dla każdej warstwy (np. listy)\"\"\"\n",
    "        \n",
    "        rozmiar_batcha = dane_wejscie.shape[1]\n",
    "        biasy = np.ones((1, rozmiar_batcha))\n",
    "\n",
    "        self.X = np.vstack([biasy, dane_wejscie]) # Dodajemy biasy\n",
    "\n",
    "        self.net = self.wagi @ self.X\n",
    "\n",
    "        dane_wyjscie = self.fun_aktywacji(self.net)\n",
    "\n",
    "        self.lista_net.append(self.net)\n",
    "        self.lista_dane_wejscie.append(self.X)\n",
    "\n",
    "        self.wyjscia_forward_prop = dane_wyjscie\n",
    "\n",
    "        return dane_wyjscie\n",
    "    \n",
    "    def back_prop(self, dL_a):\n",
    "        \"\"\"Definiujemy propagację wstecz.\n",
    "        W ostatniej warstwie liczymy funkcję straty, następnie pochodną dL/da.\"\"\"\n",
    "        \n",
    "        # Funkcja straty to L = 1/2(a[L]-y)^2, czyli pochodna z L to a[L]-y\n",
    "\n",
    "        # mamy pochodną dL/da * fi(net)\n",
    "        delta = dL_a * self.pochodna_fun_aktywacji( self.net )\n",
    "        dL_dW = delta @ self.X.T\n",
    "\n",
    "        # Liczymy dL/dX i usuwamy pierwszy element, otrzymując dL/da niższej warstwy\n",
    "        dL_dX = self.wagi.T @ delta\n",
    "        \n",
    "        # Dane do przekazania warstwę niżej\n",
    "        dL_a = dL_dX[1:]\n",
    "\n",
    "        # Aktualizujemy wagi\n",
    "        self.wagi = self.wagi - self.stala_uczenia * dL_dW\n",
    "\n",
    "        return dL_a\n",
    "    \n",
    "\n",
    "class SiecNeuronowa:\n",
    "    def __init__(self, wymiary = [784, 128, 64, 10]):\n",
    "\n",
    "        # definiujemy listę obiektów warstwy\n",
    "        self.warstwy = list()\n",
    "        # Może każdej warstwy definiujemy funkcję aktywacji? (W ten sposób można wykorzystać różne funkcje)\n",
    "\n",
    "        for i in range(len(wymiary)-1):\n",
    "            warstwa = Warstwa(wymiary[i], wymiary[i+1]) # Liczba na wejście i na wyjście\n",
    "            self.warstwy.append(warstwa)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        wejscie = X\n",
    "        \n",
    "        for warstwa in self.warstwy:\n",
    "            wejscie = warstwa.forward_prop(wejscie)\n",
    "\n",
    "        return wejscie\n",
    "            \n",
    "\n",
    "    def backward_propagation(self, y):\n",
    "\n",
    "        ostatnie_wyjscie = self.warstwy[-1].wyjscia_forward_prop\n",
    "\n",
    "        dL_da = ostatnie_wyjscie - y\n",
    "\n",
    "        for i in range(len(self.warstwy) - 1, -1, -1):\n",
    "            dL_da = self.warstwy[i].back_prop(dL_da)\n",
    "\n",
    "        return dL_da\n",
    "    \n",
    "    def krok_uczenia(self, X, y):\n",
    "        \"\"\"Definiujemy kroki dla jednej epoki\"\"\"\n",
    "\n",
    "        # Forward prop\n",
    "        y_estymowany = self.forward_propagation(X)\n",
    "\n",
    "        # Strata\n",
    "        strata = np.mean((y_estymowany - y)**2)\n",
    "\n",
    "        # Back prop\n",
    "        self.backward_propagation(y)\n",
    "\n",
    "        return strata # zwracamy wartośc funkcji straty\n",
    "\n",
    "    def fit(self, dane_w_krotkach, epoki = 10, rozmiar_batcha = 32):\n",
    "        \"\"\"Przeprowadzamy fit() dla wielu epok\"\"\"\n",
    "\n",
    "        straty = list()\n",
    "\n",
    "        for epoka in range(epoki):\n",
    "\n",
    "            strata_w_epoce = 0\n",
    "            liczba_batchy = 0\n",
    "\n",
    "            # W każdej epoce \"mieszamy\" dane\n",
    "            np.random.shuffle(dane_w_krotkach)\n",
    "\n",
    "            # dzielimy zbiór danych na porcje\n",
    "            for i in range(0, len(dane_w_krotkach), rozmiar_batcha): \n",
    "                batch = dane_w_krotkach[i:i + rozmiar_batcha]\n",
    "\n",
    "                # Wyciągamy z krotki osobno X i y\n",
    "                X_batch = np.hstack([x for x, y in batch])\n",
    "                y_batch = np.hstack([y for x, y in batch])\n",
    "                \n",
    "\n",
    "                # Strata (oraz wykonanie forward prop i back prop)\n",
    "                strata = self.krok_uczenia(X_batch, y_batch)\n",
    "                strata_w_epoce += strata\n",
    "                liczba_batchy +=1\n",
    "            \n",
    "            srednia_strata = strata_w_epoce/liczba_batchy\n",
    "            straty.append(srednia_strata)\n",
    "\n",
    "            \n",
    "        return straty\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward_propagation(X)\n",
    "\n",
    "    def dokladnosc(self, dane):\n",
    "        \"\"\" Oblicza dokładność klasyfikacji\"\"\"\n",
    "        poprawne = 0\n",
    "        liczba_danych = len(dane)\n",
    "\n",
    "        for x, y in dane:\n",
    "\n",
    "            # Z y daną cyfrę\n",
    "            y_prawdziwe = np.argmax(y)\n",
    "\n",
    "            przewidywane = self.predict(x)\n",
    "            # Wybieramy z wektora argument o najwyższej wartości\n",
    "            y_przewidywane = np.argmax(przewidywane)\n",
    "\n",
    "            # Sprawdzamy czy sieć dopasowałą poprawnie etykietę\n",
    "            if y_prawdziwe == y_przewidywane:\n",
    "                poprawne +=1\n",
    "        # Zwracamy dokładność\n",
    "        return poprawne/liczba_danych\n",
    "            \n",
    "def trenuj_siec():\n",
    "    dane_treningowe, dane_walidacyjne, dane_testowe = mnist_loader.load_data_wrapper()\n",
    "    # Pomijamy dane walidacyjne\n",
    "    dane_treningowe = list(dane_treningowe)\n",
    "    dane_testowe = list(dane_testowe)\n",
    "\n",
    "    # Tworzymy sieć\n",
    "    siec = SiecNeuronowa([784,256,128,64,10])\n",
    "\n",
    "    print(\"Trening\")\n",
    "    historia = siec.fit(dane_treningowe, epoki= 20, rozmiar_batcha= 32)\n",
    "\n",
    "    dokladnosc_trening = siec.dokladnosc(dane_treningowe)\n",
    "    dokladnosc_test = siec.dokladnosc(dane_testowe)\n",
    "\n",
    "    print(f\"Dokładność na zbiorze treningowym: {dokladnosc_trening:.4f}\")\n",
    "    print(f\"Dokładność na zbiorze testowym: {dokladnosc_test:.4f}\")\n",
    "\n",
    "    return siec, historia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eeab689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trening\n",
      "Dokładność na zbiorze treningowym: 0.9919\n",
      "Dokładność na zbiorze testowym: 0.9778\n"
     ]
    }
   ],
   "source": [
    "siec, historia = trenuj_siec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeea3e9",
   "metadata": {},
   "source": [
    "Mamy dobre wyniki dla:\n",
    "* warstwy = [784,128,64,10], epoki = 5, rozmiar batcha = 32, stała uczenia = 0.1\n",
    "* warstwy = [784,128,64,32,10], epoki = 20, rozmiar batcha = 128, stała uczenia = 0.1\n",
    "\n",
    "Ogólne wnioski:\n",
    "* [784,256,64,10] np. dla takiej sieci wyniki są słabe, po 10*, nawet dla 20 epok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a69ed1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoki')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historia)\n",
    "plt.title(\"Wartość funkcji straty w epokach\")\n",
    "plt.xlabel(\"Epoki\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2201dd0",
   "metadata": {},
   "source": [
    "### Empiryczne sprawdzenie, czy Warstwa jest poprawnie zaimplementowana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82ec2357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wagi: (2, 3)\n",
      "a[1]\n",
      "dane_wejscie.shape (2, 1)\n",
      "self.X.shape (3, 1)\n",
      "wagi (2, 3)\n",
      "self.X.shape (2, 1)\n",
      "dane_wyjscie (2, 1)\n",
      "[[0.42555748]\n",
      " [0.57444252]]\n",
      "dane_wejscie.shape (2, 1)\n",
      "self.X.shape (3, 1)\n",
      "wagi (2, 3)\n",
      "self.X.shape (2, 1)\n",
      "dane_wyjscie (2, 1)\n",
      "wagi: (2, 3)\n",
      "dane_wejscie.shape (2, 1)\n",
      "self.X.shape (3, 1)\n",
      "wagi (2, 3)\n",
      "self.X.shape (2, 1)\n",
      "dane_wyjscie (2, 1)\n",
      "a[2]\n",
      "[[0.45754671]\n",
      " [0.37654958]]\n",
      "dL_da2\n",
      "[[ 0.45754671]\n",
      " [-0.62345042]]\n",
      "\n",
      "delta\n",
      "[[ 0.11356205]\n",
      " [-0.14636122]]\n",
      "dL_dW\n",
      "[[ 0.11356205  0.04832718  0.06523487]\n",
      " [-0.14636122 -0.06228511 -0.08407611]]\n",
      "dL_da1\n",
      "[[-0.13816143]\n",
      " [ 0.1121691 ]]\n",
      "nowe_wagi dla warstwy 2\n",
      "[[-0.16135621 -0.25483272  0.14347651]\n",
      " [-0.43536388  0.75622851 -0.64159239]]\n",
      "Obliczenia dla warstwy niżej\n",
      "\n",
      "delta\n",
      "[[-0.03377471]\n",
      " [ 0.02742067]]\n",
      "dL_dW\n",
      "[[-0.03377471 -0.03377471  0.        ]\n",
      " [ 0.02742067  0.02742067  0.        ]]\n",
      "dL_da0\n",
      "[[ 0.02594941]\n",
      " [-0.01982987]]\n",
      "nowe wagi dla warstwy 1\n",
      "[[-0.09662253 -0.19662253  0.1       ]\n",
      " [-0.40274207  0.69725793 -0.6       ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,0]).reshape(2,1)\n",
    "y = np.array([0,1]).reshape(2,1)\n",
    "W1 = np.array([[-0.1, -0.2, 0.1],\n",
    "               [-0.4, 0.7, -0.6]])\n",
    "W2 = np.array([[-0.15, -0.25, 0.15],\n",
    "               [-0.45, 0.75, -0.65]])\n",
    "X1 = np.vstack((1,x))\n",
    "\n",
    "warstwa1 = Warstwa(2,2)\n",
    "warstwa1.wagi = W1\n",
    "print(\"a[1]\")\n",
    "print(warstwa1.forward_prop(x)) # dostajemy a[1] z przykładu ML_06\n",
    "a1 = warstwa1.forward_prop(x)\n",
    "\n",
    "\n",
    "warstwa2 = Warstwa(2,2)\n",
    "warstwa2.wagi = W2\n",
    "#print(warstwa2.wagi)\n",
    "a2 = warstwa2.forward_prop(a1)\n",
    "print(\"a[2]\")\n",
    "print(a2)\n",
    "\n",
    "# Czyli forward_prop działa\n",
    "# Sprawdźmy back_prop\n",
    "\n",
    "#w back_prop podajemy dL_da[k], otrzymując w ten sposób dL_da[k-1] z niższej warstwy (w międzyczasie aktualizujemy wagi)\n",
    "dL_da2 = a2 - y\n",
    "print(\"dL_da2\")\n",
    "print(dL_da2)\n",
    "print()\n",
    "\n",
    "dL_da1 = warstwa2.back_prop(dL_da2)\n",
    "print(\"dL_da1\")\n",
    "print(dL_da1)\n",
    "warstwa2.lista_net #mamy net1\n",
    "\n",
    "print(\"nowe_wagi dla warstwy 2\")\n",
    "print(warstwa2.wagi)\n",
    "############################## Kolejna warstwa ##########################\n",
    "\n",
    "print(\"Obliczenia dla warstwy niżej\")\n",
    "print()\n",
    "\n",
    "dL_da0 = warstwa1.back_prop(dL_da1)\n",
    "print(\"dL_da0\")\n",
    "print(dL_da0)\n",
    "\n",
    "print(\"nowe wagi dla warstwy 1\")\n",
    "print(warstwa1.wagi)\n",
    "# Zwraca poprawne wyniki\n",
    "# Czyli forward i back prop są dobrze zdefiniowane\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588168ea",
   "metadata": {},
   "source": [
    "Możemy ulepszyć tę sieć dodając np:\n",
    "* Osobną funkcję aktywacji dla każdej warsty np ReLU\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3720cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39961c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wagi: (2, 3)\n",
      "wagi: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "siec = SiecNeuronowa(wymiary=[2,2,2])\n",
    "siec.warstwy[0] = warstwa1\n",
    "siec.warstwy[1] = warstwa2\n",
    "\n",
    "#siec.forward_propagation(x)\n",
    "#siec.backward_propagation(dL_da2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377e5f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2],[3,4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ebe4a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "(1, 4)\n",
      "[[1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "A_kolumnowy = A.reshape(-1,1) # kolumnowy\n",
    "A_wierszowy = A.reshape(1,-1) \n",
    "print(A_kolumnowy.shape)\n",
    "print(A_wierszowy.shape)\n",
    "print(A_wierszowy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "768174ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.ones((4,1))\n",
    "print(b)\n",
    "polaczone = np.hstack([b,A_kolumnowy])\n",
    "polaczone.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4acea84",
   "metadata": {},
   "source": [
    "# Wersja z zadawaniem funkcji aktywacji dla warstwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "010499cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wygeneruj_wagi(wymiar_wejscie, wymiar_wyjscie):\n",
    "    # wyjściem jest liczba neuronów w następnej warstwie\n",
    "    wektor_wag = np.random.normal(0,1/math.sqrt(wymiar_wejscie),(1+wymiar_wejscie)*wymiar_wyjscie)\n",
    "    return np.reshape(wektor_wag, (wymiar_wyjscie, 1+wymiar_wejscie )  )\n",
    "\n",
    "# Definiujemy funkcje aktywacji fi (sigmoid)\n",
    "# fi' = fi*(1-fi) \n",
    "def sigmoid(x): return (1+np.exp(-x))**(-1) \n",
    "\n",
    "def deriv_sigmoid(x): return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "# Definiujemy funkcję aktywacji ReLU\n",
    "def relu(x): return np.maximum(0,x) # maximum zwraca macierz\n",
    "\n",
    "def deriv_relu(x): return np.where(x>0, 1,0)\n",
    "\n",
    "\n",
    "class Warstwa:\n",
    "    def __init__(self, liczba_wejscie, liczba_neuronow, funkcja_aktywacji = \"sigmoid\"):\n",
    "        \"\"\"liczba neuronów - w warstwie (czyli liczba danych na wyjściu)\"\"\"\n",
    "        self.liczba_neuronow = liczba_neuronow\n",
    "\n",
    "        self.liczba_wejscie = liczba_wejscie\n",
    "        \n",
    "        # Ustalamy stałą uczenia dla całej warstwy\n",
    "        self.stala_uczenia = 0.03\n",
    "\n",
    "        # Inicjalizacja wag\n",
    "        self.wagi = wygeneruj_wagi(self.liczba_wejscie, self.liczba_neuronow)\n",
    "        \n",
    "        # Funkcja aktywacji, która będzie wykorzystana w danej warstwie\n",
    "        self.funkcja_aktywacji = funkcja_aktywacji\n",
    "\n",
    "        # Rzeczy do zapamiętania,\n",
    "        #  Może wystarczy zapamiętać tylko ostatnie wartosci\n",
    "        self.lista_dane_wejscie = list()\n",
    "        self.lista_net = list()\n",
    "    \n",
    "\n",
    "    def fun_aktywacji(self, x): \n",
    "        if self.funkcja_aktywacji == \"sigmoid\": \n",
    "            return sigmoid(x)\n",
    "        elif self.funkcja_aktywacji == \"relu\": \n",
    "            return relu(x)\n",
    "\n",
    "    def pochodna_fun_aktywacji(self, x):\n",
    "        if self.funkcja_aktywacji == \"sigmoid\": \n",
    "            return deriv_sigmoid(x)\n",
    "        elif self.funkcja_aktywacji == \"relu\": \n",
    "            return deriv_relu(x)\n",
    "\n",
    "    def forward_prop(self, dane_wejscie ):\n",
    "        \"\"\"Definiujemy propagację w przód.\n",
    "        Podajemy dane na wejście, dodajemy na bias = 1 na początek wektora (otrzymujemy w ten sposób X).\n",
    "        Zadajemy najpierw ile chcemy mieć neuronów na wyjściu\n",
    "        Nastepnie liczymy net = W*X <- wyjście netto.\n",
    "        Póżniej nakładamy funkcję aktywacji fi na net, otrzymując fi(net) = a <- wyjście z warstwy.\n",
    "        Musimy też zapisywać stany x, net, a dla każdej warstwy (np. listy)\"\"\"\n",
    "        \n",
    "        rozmiar_batcha = dane_wejscie.shape[1]\n",
    "        biasy = np.ones((1, rozmiar_batcha))\n",
    "\n",
    "        self.X = np.vstack([biasy, dane_wejscie]) # Dodajemy biasy\n",
    "\n",
    "        self.net = self.wagi @ self.X\n",
    "\n",
    "        dane_wyjscie = self.fun_aktywacji(self.net)\n",
    "\n",
    "        self.lista_net.append(self.net)\n",
    "        self.lista_dane_wejscie.append(self.X)\n",
    "\n",
    "        self.wyjscia_forward_prop = dane_wyjscie\n",
    "\n",
    "        return dane_wyjscie\n",
    "    \n",
    "    def back_prop(self, dL_a):\n",
    "        \"\"\"Definiujemy propagację wstecz.\n",
    "        W ostatniej warstwie liczymy funkcję straty, następnie pochodną dL/da.\"\"\"\n",
    "        \n",
    "        # Funkcja straty to L = 1/2(a[L]-y)^2, czyli pochodna z L to a[L]-y\n",
    "\n",
    "        # mamy pochodną dL/da * fi(net)\n",
    "        delta = dL_a * self.pochodna_fun_aktywacji( self.net )\n",
    "        dL_dW = delta @ self.X.T\n",
    "\n",
    "        # Liczymy dL/dX i usuwamy pierwszy element, otrzymując dL/da niższej warstwy\n",
    "        dL_dX = self.wagi.T @ delta\n",
    "        \n",
    "        # Dane do przekazania warstwę niżej\n",
    "        dL_a = dL_dX[1:]\n",
    "\n",
    "        # Aktualizujemy wagi\n",
    "        self.wagi = self.wagi - self.stala_uczenia * dL_dW\n",
    "\n",
    "        return dL_a\n",
    "    \n",
    "\n",
    "class SiecNeuronowa:\n",
    "    def __init__(self, wymiary = [784, 128, 64, 10], funkcje_aktywacji=None):\n",
    "\n",
    "        # Definiujemy domyślne funkcje aktywacji dla warstw (np. sigmoid)\n",
    "        if funkcje_aktywacji == None:\n",
    "            funkcje_aktywacji = [\"sigmoid\"]*(len(wymiary)-1)\n",
    "\n",
    "        # definiujemy listę obiektów warstwy\n",
    "        self.warstwy = list()\n",
    "        # Może każdej warstwy definiujemy funkcję aktywacji? (W ten sposób można wykorzystać różne funkcje)\n",
    "\n",
    "        for i in range(len(wymiary)-1):\n",
    "            warstwa = Warstwa(wymiary[i], wymiary[i+1], funkcje_aktywacji[i]) # Liczba na wejście i na wyjście\n",
    "            self.warstwy.append(warstwa)\n",
    "            print(f\"Warstwa {i}: {wymiary[i]} -> {wymiary[i+1]}, funkcja {funkcje_aktywacji[i]}\")\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        wejscie = X\n",
    "        \n",
    "        for warstwa in self.warstwy:\n",
    "            wejscie = warstwa.forward_prop(wejscie)\n",
    "\n",
    "        return wejscie\n",
    "            \n",
    "\n",
    "    def backward_propagation(self, y):\n",
    "\n",
    "        ostatnie_wyjscie = self.warstwy[-1].wyjscia_forward_prop\n",
    "\n",
    "        dL_da = ostatnie_wyjscie - y\n",
    "\n",
    "        for i in range(len(self.warstwy) - 1, -1, -1):\n",
    "            dL_da = self.warstwy[i].back_prop(dL_da)\n",
    "\n",
    "        return dL_da\n",
    "    \n",
    "    def krok_uczenia(self, X, y):\n",
    "        \"\"\"Definiujemy kroki dla jednej epoki\"\"\"\n",
    "\n",
    "        # Forward prop\n",
    "        y_estymowany = self.forward_propagation(X)\n",
    "\n",
    "        # Strata\n",
    "        strata = np.mean((y_estymowany - y)**2)\n",
    "\n",
    "        # Back prop\n",
    "        self.backward_propagation(y)\n",
    "\n",
    "        return strata # zwracamy wartośc funkcji straty\n",
    "\n",
    "    def fit(self, dane_w_krotkach, epoki = 10, rozmiar_batcha = 32):\n",
    "        \"\"\"Przeprowadzamy fit() dla wielu epok\"\"\"\n",
    "\n",
    "        straty = list()\n",
    "\n",
    "        for epoka in range(epoki):\n",
    "\n",
    "            strata_w_epoce = 0\n",
    "            liczba_batchy = 0\n",
    "\n",
    "            # W każdej epoce \"mieszamy\" dane\n",
    "            np.random.shuffle(dane_w_krotkach)\n",
    "\n",
    "            # dzielimy zbiór danych na porcje\n",
    "            for i in range(0, len(dane_w_krotkach), rozmiar_batcha): \n",
    "                batch = dane_w_krotkach[i:i + rozmiar_batcha]\n",
    "\n",
    "                # Wyciągamy z krotki osobno X i y\n",
    "                X_batch = np.hstack([x for x, y in batch])\n",
    "                y_batch = np.hstack([y for x, y in batch])\n",
    "                \n",
    "\n",
    "                # Strata (oraz wykonanie forward prop i back prop)\n",
    "                strata = self.krok_uczenia(X_batch, y_batch)\n",
    "                strata_w_epoce += strata\n",
    "                liczba_batchy +=1\n",
    "            \n",
    "            srednia_strata = strata_w_epoce/liczba_batchy\n",
    "            straty.append(srednia_strata)\n",
    "\n",
    "            \n",
    "        return straty\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward_propagation(X)\n",
    "\n",
    "    def dokladnosc(self, dane):\n",
    "        \"\"\" Oblicza dokładność klasyfikacji\"\"\"\n",
    "        poprawne = 0\n",
    "        liczba_danych = len(dane)\n",
    "\n",
    "        for x, y in dane:\n",
    "\n",
    "            # Z y daną cyfrę\n",
    "            y_prawdziwe = np.argmax(y)\n",
    "\n",
    "            przewidywane = self.predict(x)\n",
    "            # Wybieramy z wektora argument o najwyższej wartości\n",
    "            y_przewidywane = np.argmax(przewidywane)\n",
    "\n",
    "            # Sprawdzamy czy sieć dopasowałą poprawnie etykietę\n",
    "            if y_prawdziwe == y_przewidywane:\n",
    "                poprawne +=1\n",
    "        # Zwracamy dokładność\n",
    "        return poprawne/liczba_danych\n",
    "            \n",
    "def trenuj_siec():\n",
    "    dane_treningowe, dane_walidacyjne, dane_testowe = mnist_loader.load_data_wrapper()\n",
    "    # Pomijamy dane walidacyjne\n",
    "    dane_treningowe = list(dane_treningowe)\n",
    "    dane_testowe = list(dane_testowe)\n",
    "\n",
    "    # Tworzymy sieć\n",
    "    fun_akt_sig = [\"sigmoid\",\"sigmoid\",\"sigmoid\",\"sigmoid\"]\n",
    "    fun_akt_relu_sig = [\"relu\",\"relu\",\"sigmoid\"]\n",
    "    fun_akt_relu = [\"relu\",\"relu\",\"relu\"]\n",
    "    siec = SiecNeuronowa([784,128,64,10], funkcje_aktywacji=fun_akt_sig)\n",
    "\n",
    "    print(\"Trening\")\n",
    "    historia = siec.fit(dane_treningowe, epoki= 10, rozmiar_batcha= 100)\n",
    "\n",
    "    dokladnosc_trening = siec.dokladnosc(dane_treningowe)\n",
    "    dokladnosc_test = siec.dokladnosc(dane_testowe)\n",
    "\n",
    "    print(f\"Dokładność na zbiorze treningowym: {100*dokladnosc_trening:.4f} %\")\n",
    "    print(f\"Dokładność na zbiorze testowym: {100*dokladnosc_test:.4f} %\")\n",
    "\n",
    "    return siec, historia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "50413b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warstwa 0: 784 -> 128, funkcja sigmoid\n",
      "Warstwa 1: 128 -> 64, funkcja sigmoid\n",
      "Warstwa 2: 64 -> 10, funkcja sigmoid\n",
      "Trening\n",
      "Dokładność na zbiorze treningowym: 96.9440 %\n",
      "Dokładność na zbiorze testowym: 96.2500 %\n"
     ]
    }
   ],
   "source": [
    "siec, historia = trenuj_siec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9478aa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoki')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historia)\n",
    "plt.title(\"Wartość funkcji straty w epokach\")\n",
    "plt.xlabel(\"Epoki\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e2a2f",
   "metadata": {},
   "source": [
    "Mamy dobre wyniki dla:\n",
    "* warstwy = [784,128,64,10], epoki = 5, rozmiar batcha = 32, stała uczenia = 0.1\n",
    "* warstwy = [784,128,64,32,10], epoki = 20, rozmiar batcha = 128, stała uczenia = 0.1\n",
    "\n",
    "Ogólne wnioski:\n",
    "* [784,256,64,10] np. dla takiej sieci wyniki są słabe, po 10*, nawet dla 20 epok\n",
    "* ReLU na ostatniej warstwie znacznie pogarsza wynik, co było spodziewane. Wyniki Softmax i Sigmoid możemy traktować jak prawdopodobieństwa (przymują wartości z zakresu (0,1)), zatem są lepsze w przypadku ostatniej warstwy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5e2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
